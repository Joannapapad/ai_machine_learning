{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data through keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "vocabulary_size = 4000 \n",
    "n = 100  # Αριθμός πιο συχνών λέξεων που θα αφαιρεθούν\n",
    "k = 50   # Αριθμός πιο σπάνιων λέξεων που θα αφαιρεθούν\n",
    "m = 3000 # Αριθμός λέξεων με το υψηλότερο πληροφοριακό κέρδος\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "word_index = imdb.get_word_index() # dictionary mapping words to their corresponding integer indices\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "x_train_text = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
    "x_test_text = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for text in x_train_text:\n",
    "    tokens = text.split()\n",
    "    vocabulary.update(tokens)\n",
    "\n",
    "most_common_words = [word for word, _ in vocabulary.most_common(n)]\n",
    "least_common_words = [word for word, _ in vocabulary.most_common()[:-k-1:-1]]\n",
    "\n",
    "filtered_vocabulary = [word for word in vocabulary.keys() \n",
    "                       if word not in most_common_words and word not in least_common_words]\n",
    "\n",
    "filtered_vocabulary = list(filtered_vocabulary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Binary Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def create_binary_vectors(texts, vocabulary):\n",
    "  binary_vectors = []\n",
    "\n",
    "  for text in tqdm(texts):\n",
    "    tokens = text.split()\n",
    "    b_vector = list()\n",
    "    for vocab_token in vocabulary:\n",
    "      if vocab_token in tokens:\n",
    "        b_vector.append(1)\n",
    "      else:\n",
    "        b_vector.append(0)\n",
    "    binary_vectors.append(b_vector)\n",
    "\n",
    "  return np.array(binary_vectors)\n",
    "\n",
    "x_train_binary = create_binary_vectors(x_train_text, filtered_vocabulary)\n",
    "\n",
    "# πληροφοριακο κερδος\n",
    "mutual_info = mutual_info_classif(x_train_binary, y_train, discrete_features=True)\n",
    "# Επιλογή m λέξεων με το υψηλότερο πληροφοριακό κέρδος\n",
    "top_m_indices = np.argsort(mutual_info)[-m:]\n",
    "final_vocabulary = [filtered_vocabulary[i] for i in top_m_indices]\n",
    "\n",
    "# Μετατροπή των δεδομένων σε διανύσματα βάσει του τελικού λεξιλογίου\n",
    "x_train_binary_final = create_binary_vectors(x_train_text, final_vocabulary)\n",
    "x_test_binary_final = create_binary_vectors(x_test_text, final_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Naive Bayes Classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}  # Prior P(C)\n",
    "        self.feature_probs = {}  # Likelihood P(X | C)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the Bernoulli Naive Bayes classifier.\n",
    "        :param X: Binary feature matrix (num_samples, num_features)\n",
    "        :param y: Labels (num_samples,)\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        # Calculate priors P(C)\n",
    "        for cls in unique_classes:\n",
    "            class_count = np.sum(y == cls)\n",
    "            self.class_priors[cls] = class_count / n_samples\n",
    "\n",
    "        # Calculate likelihoods P(X | C)\n",
    "        for cls in unique_classes:\n",
    "            # Select samples belonging to this class\n",
    "            X_class = X[y == cls]\n",
    "            # Compute probabilities for each feature\n",
    "            feature_prob = (np.sum(X_class, axis=0) + 1) / (X_class.shape[0] + 2)  # Laplace smoothing\n",
    "            self.feature_probs[cls] = feature_prob\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class for each sample in X.\n",
    "        :param X: Binary feature matrix (num_samples, num_features)\n",
    "        :return: Predicted labels\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for x in X:\n",
    "            class_scores = {}\n",
    "            for cls in self.class_priors:\n",
    "                # Start with the log prior\n",
    "                score = np.log(self.class_priors[cls])\n",
    "\n",
    "                # Add the log likelihoods\n",
    "                feature_prob = self.feature_probs[cls]\n",
    "                score += np.sum(np.log(feature_prob) * x + np.log(1 - feature_prob) * (1 - x))\n",
    "                class_scores[cls] = score\n",
    "\n",
    "            # Choose the class with the highest score\n",
    "            predictions.append(max(class_scores, key=class_scores.get))\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# Training the Bernoulli Naive Bayes classifier\n",
    "nb_classifier = BernoulliNaiveBayes()\n",
    "nb_classifier.fit(x_train_binary_final, y_train)\n",
    "\n",
    "# Testing the classifier\n",
    "y_pred = nb_classifier.predict(x_test_binary_final)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagrams and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Δημιουργία συνάρτησης για καμπύλες μάθησης\n",
    "def learning_curves(model, X_train, y_train, X_dev, y_dev, step_size=1000):\n",
    "    \"\"\"\n",
    "    Υπολογισμός καμπυλών μάθησης για διαφορετικά μεγέθη εκπαίδευσης.\n",
    "    :param model: Το μοντέλο Naive Bayes\n",
    "    :param X_train: Δεδομένα εκπαίδευσης\n",
    "    :param y_train: Ετικέτες εκπαίδευσης\n",
    "    :param X_dev: Δεδομένα ανάπτυξης\n",
    "    :param y_dev: Ετικέτες ανάπτυξης\n",
    "    :param step_size: Βήμα αύξησης του μεγέθους εκπαίδευσης\n",
    "    :return: Λίστες με ακρίβεια, ανάκληση, και F1-score\n",
    "    \"\"\"\n",
    "    training_sizes = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(step_size, len(X_train) + 1, step_size):\n",
    "        # Training subset\n",
    "        X_subset = X_train[:i]\n",
    "        y_subset = y_train[:i]\n",
    "\n",
    "        # Verify alignment of subset\n",
    "        assert len(X_subset) == len(y_subset), \"Mismatch between X_subset and y_subset lengths\"\n",
    "\n",
    "        # Εκπαίδευση του μοντέλου\n",
    "        model.fit(X_subset, y_subset)\n",
    "\n",
    "        # Πρόβλεψη στα δεδομένα ανάπτυξης\n",
    "        y_pred = model.predict(X_dev)\n",
    "\n",
    "        # Υπολογισμός ακρίβειας, ανάκλησης, και F1\n",
    "        precision = precision_score(y_dev, y_pred, average='binary')\n",
    "        recall = recall_score(y_dev, y_pred, average='binary')\n",
    "        f1 = f1_score(y_dev, y_pred, average='binary')\n",
    "\n",
    "        # Αποθήκευση αποτελεσμάτων\n",
    "        training_sizes.append(i)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return training_sizes, precisions, recalls, f1_scores\n",
    "\n",
    "# Δημιουργία γραφημάτων\n",
    "def plot_learning_curves(training_sizes, precisions, recalls, f1_scores):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(training_sizes, precisions, label=\"Precision\")\n",
    "    plt.plot(training_sizes, recalls, label=\"Recall\")\n",
    "    plt.plot(training_sizes, f1_scores, label=\"F1-score\")\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Εφαρμογή του μοντέλου και υπολογισμός καμπυλών\n",
    "nb_classifier = BernoulliNaiveBayes()\n",
    "\n",
    "# Δημιουργία δεδομένων ανάπτυξης από τα δεδομένα εκπαίδευσης\n",
    "dev_size = int(0.1 * len(x_train_binary_final))  # 10% ως development set\n",
    "X_dev = x_train_binary_final[:dev_size]\n",
    "y_dev = y_train[:dev_size]\n",
    "\n",
    "X_train = x_train_binary_final[dev_size:]\n",
    "y_train = y_train[dev_size:]\n",
    "\n",
    "# Υπολογισμός καμπυλών μάθησης\n",
    "training_sizes, precisions, recalls, f1_scores = learning_curves(\n",
    "    nb_classifier, X_train, y_train, X_dev, y_dev\n",
    ")\n",
    "\n",
    "# Σχεδίαση καμπυλών\n",
    "plot_learning_curves(training_sizes, precisions, recalls, f1_scores)\n",
    "\n",
    "# Υπολογισμός τελικών αποτελεσμάτων στα δεδομένα αξιολόγησης\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_test_pred = nb_classifier.predict(x_test_binary_final)\n",
    "\n",
    "# Ακρίβεια, Ανάκληση και F1 για κατηγορίες και μέσα (macro, micro)\n",
    "precision_pos = precision_score(y_test, y_test_pred, pos_label=1)\n",
    "recall_pos = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "f1_pos = f1_score(y_test, y_test_pred, pos_label=1)\n",
    "\n",
    "precision_neg = precision_score(y_test, y_test_pred, pos_label=0)\n",
    "recall_neg = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "f1_neg = f1_score(y_test, y_test_pred, pos_label=0)\n",
    "\n",
    "precision_macro = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "recall_macro = recall_score(y_test, y_test_pred, average=\"macro\")\n",
    "f1_macro = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "\n",
    "precision_micro = precision_score(y_test, y_test_pred, average=\"micro\")\n",
    "recall_micro = recall_score(y_test, y_test_pred, average=\"micro\")\n",
    "f1_micro = f1_score(y_test, y_test_pred, average=\"micro\")\n",
    "\n",
    "# Εκτύπωση αποτελεσμάτων\n",
    "print(\"Precision (Positive):\", precision_pos)\n",
    "print(\"Recall (Positive):\", recall_pos)\n",
    "print(\"F1 (Positive):\", f1_pos)\n",
    "\n",
    "print(\"Precision (Negative):\", precision_neg)\n",
    "print(\"Recall (Negative):\", recall_neg)\n",
    "print(\"F1 (Negative):\", f1_neg)\n",
    "\n",
    "print(\"Macro-averaged Precision:\", precision_macro)\n",
    "print(\"Macro-averaged Recall:\", recall_macro)\n",
    "print(\"Macro-averaged F1:\", f1_macro)\n",
    "\n",
    "print(\"Micro-averaged Precision:\", precision_micro)\n",
    "print(\"Micro-averaged Recall:\", recall_micro)\n",
    "print(\"Micro-averaged F1:\", f1_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Μερος Β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Bernoulli Naive Bayes Accuracy: 0.85\n",
      "Scikit-learn BernoulliNB Performance\n",
      "Precision (Positive): 0.8542573281878644\n",
      "Recall (Positive): 0.83232\n",
      "F1 (Positive): 0.8431459945702824\n",
      "Precision (Negative): 0.8365182123079323\n",
      "Recall (Negative): 0.858\n",
      "F1 (Negative): 0.8471229414320129\n",
      "Macro-averaged Precision: 0.8453877702478984\n",
      "Macro-averaged Recall: 0.8451599999999999\n",
      "Macro-averaged F1: 0.8451344680011477\n",
      "Micro-averaged Precision: 0.84516\n",
      "Micro-averaged Recall: 0.84516\n",
      "Micro-averaged F1: 0.84516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Train the Scikit-learn Bernoulli Naive Bayes classifier using the binary vectors\n",
    "bnb_sklearn = BernoulliNB()  \n",
    "bnb_sklearn.fit(x_train_binary_final, y_train)\n",
    "\n",
    "y_pred_sklearn = bnb_sklearn.predict(x_test_binary_final)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_sklearn = np.mean(y_pred_sklearn == y_test)\n",
    "print(f\"Scikit-learn Bernoulli Naive Bayes Accuracy: {accuracy_sklearn:.2f}\")\n",
    "\n",
    "# Precision, Recall, and F1 for positive class (1)\n",
    "precision_pos_sklearn = precision_score(y_test, y_pred_sklearn, pos_label=1)\n",
    "recall_pos_sklearn = recall_score(y_test, y_pred_sklearn, pos_label=1)\n",
    "f1_pos_sklearn = f1_score(y_test, y_pred_sklearn, pos_label=1)\n",
    "\n",
    "# Precision, Recall, and F1 for negative class (0)\n",
    "precision_neg_sklearn = precision_score(y_test, y_pred_sklearn, pos_label=0)\n",
    "recall_neg_sklearn = recall_score(y_test, y_pred_sklearn, pos_label=0)\n",
    "f1_neg_sklearn = f1_score(y_test, y_pred_sklearn, pos_label=0)\n",
    "\n",
    "# Macro and Micro averages\n",
    "precision_macro_sklearn = precision_score(y_test, y_pred_sklearn, average=\"macro\")\n",
    "recall_macro_sklearn = recall_score(y_test, y_pred_sklearn, average=\"macro\")\n",
    "f1_macro_sklearn = f1_score(y_test, y_pred_sklearn, average=\"macro\")\n",
    "\n",
    "precision_micro_sklearn = precision_score(y_test, y_pred_sklearn, average=\"micro\")\n",
    "recall_micro_sklearn = recall_score(y_test, y_pred_sklearn, average=\"micro\")\n",
    "f1_micro_sklearn = f1_score(y_test, y_pred_sklearn, average=\"micro\")\n",
    "\n",
    "# Print Scikit-learn results\n",
    "print(\"Scikit-learn BernoulliNB Performance\")\n",
    "print(f\"Precision (Positive): {precision_pos_sklearn}\")\n",
    "print(f\"Recall (Positive): {recall_pos_sklearn}\")\n",
    "print(f\"F1 (Positive): {f1_pos_sklearn}\")\n",
    "\n",
    "print(f\"Precision (Negative): {precision_neg_sklearn}\")\n",
    "print(f\"Recall (Negative): {recall_neg_sklearn}\")\n",
    "print(f\"F1 (Negative): {f1_neg_sklearn}\")\n",
    "\n",
    "print(f\"Macro-averaged Precision: {precision_macro_sklearn}\")\n",
    "print(f\"Macro-averaged Recall: {recall_macro_sklearn}\")\n",
    "print(f\"Macro-averaged F1: {f1_macro_sklearn}\")\n",
    "\n",
    "print(f\"Micro-averaged Precision: {precision_micro_sklearn}\")\n",
    "print(f\"Micro-averaged Recall: {recall_micro_sklearn}\")\n",
    "print(f\"Micro-averaged F1: {f1_micro_sklearn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compare the learning curves of different models\n",
    "def compare_learning_curves(models, X_train, y_train, X_dev, y_dev, step_size=1000):\n",
    "    training_sizes = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(step_size, len(X_train) + 1, step_size):\n",
    "        # Training subset\n",
    "        X_subset = X_train[:i]\n",
    "        y_subset = y_train[:i]\n",
    "\n",
    "        # Verify alignment of subset\n",
    "        assert len(X_subset) == len(y_subset), \"Mismatch between X_subset and y_subset lengths\"\n",
    "\n",
    "        # Store results for each model\n",
    "        for model_name, model in models.items():\n",
    "            model.fit(X_subset, y_subset)\n",
    "            y_pred = model.predict(X_dev)\n",
    "\n",
    "            precision = precision_score(y_dev, y_pred, average='binary')\n",
    "            recall = recall_score(y_dev, y_pred, average='binary')\n",
    "            f1 = f1_score(y_dev, y_pred, average='binary')\n",
    "\n",
    "            # Append results\n",
    "            training_sizes.append(i)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "    return training_sizes, precisions, recalls, f1_scores\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Custom BNB\": nb_classifier,\n",
    "    \"Scikit-learn BNB\": bnb_sklearn,\n",
    "    \"MLP Classifier\": mlp\n",
    "}\n",
    "\n",
    "# Compare learning curves\n",
    "training_sizes, precisions, recalls, f1_scores = compare_learning_curves(\n",
    "    models, X_train, y_train, X_dev, y_dev\n",
    ")\n",
    "\n",
    "# Plot learning curves\n",
    "plot_learning_curves(training_sizes, precisions, recalls, f1_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
